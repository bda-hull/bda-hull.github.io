<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

	<title>Big Data Analytics Research Group</title>

	<!-- Google font -->
	<link href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CVarela+Round" rel="stylesheet">

	<!-- Bootstrap -->
	<link type="text/css" rel="stylesheet" href="css/bootstrap.min.css" />

	<!-- Owl Carousel -->
	<link type="text/css" rel="stylesheet" href="css/owl.carousel.css" />
	<link type="text/css" rel="stylesheet" href="css/owl.theme.default.css" />

	<!-- Magnific Popup -->
	<link type="text/css" rel="stylesheet" href="css/magnific-popup.css" />

	<!-- Font Awesome Icon -->
	<link rel="stylesheet" href="css/font-awesome.min.css">

	<!-- Custom stlylesheet -->
	<link type="text/css" rel="stylesheet" href="css/style.css" />

	<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
	<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
	<!--[if lt IE 9]>
		<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
		<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
</head>

<body>

	<!-- Header -->
	<header>

		<!-- Nav -->
		<nav id="nav" class="navbar">
			<div class="container">

				<div class="navbar-header">
					<!-- Logo -->
					<div class="navbar-brand">
						<a href="index.html">
							<img class="logo" src="img/logo.png" alt="logo">
						</a>
					</div>
					<!-- /Logo -->

					<!-- Collapse nav button -->
					<div class="nav-collapse">
						<span></span>
					</div>
					<!-- /Collapse nav button -->
				</div>

			<!--  Main navigation  -->
				<ul class="main-nav nav navbar-nav navbar-right">
					<li><a href="index.html#home">Home</a></li>
					<li><a href="index.html#research">Research</a>
					<li><a href="publications.html">Publications</a></li>
					<li><a href="index.html#team">Team</a></li>
					<li><a href="index.html#news">News, Projects + Activities</a></li>
					<li><a href="index.html#contact">Contact</a></li>
				</ul>
				<!-- /Main navigation -->

			</div>
		</nav>
		<!-- /Nav -->

		<!-- header wrapper -->
		<div class="header-wrapper sm-padding bg-grey">
			<div class="container">
				<h2>NATURAL LANGUAGE PROCESSING</h2>
				<ul class="breadcrumb">
					<li class="breadcrumb-item"><a href="index.html">Home</a></li>
					<li class="breadcrumb-item"><a href="index.html#research">Research</a></li>
				</ul>
			</div>
		</div>
		<!-- /header wrapper -->

	</header>
	<!-- /Header -->

	<!-- Blog -->
	<div id="blog" class="section md-padding">

		<!-- Container -->
		<div class="container">
			<!-- Row -->
			<div class="row">

				<!-- Main -->
				<main id="main" class="col-md-9">
					<div class="blog">
						<div class="blog-img">
<!--					<img class="img-responsive" src="./img/tree.jpg" alt="">-->
						</div>
						<div class="blog-content">

							<h3><br/> Our Natural Language Processing Research</h3>
							<p>Natural language generation (NLP) refers to approaches that analyse, generate and process natural language automatically using computational techniques and algorithms, mostly based on machine learning. Our strengths lie in natural language generation, (spoken) dialogue systems, sentiment analysis and linguistic analyses that can inform automatic NLP. <br/><br/></p>
							
							<h5>Natural Language Generation</h5>
								<img class="img-responsive" src="./img/nlg.jpg" alt="" width="500" align="right">	
							<p>Natural language generation transfers a non-linguistic input representation to a human-understandable text that can be accompanied by illustrations, pictures or other supporting material. Inputs can be structured information such as a knowledge graph, tabular representation or sensor outputs or an unstructured representation such as free text, image pixels or other semi-structured data source. The goal is to generate a new text or sometimes a summary that captures the most important aspects of the input while potentially adapting to different <a href="publications/nle2015.pdf">contexts</a>, <a href="publications/scc2011.pdf">information needs</a> or <a href="publications/eacl2014.pdf">audiences</a> that will benefit from the information.</p>	
											
							<p>Current projects include KGen - Natural language generation from a Knowledge Graph - a collaboration with Stanford AI start-up <a href="https://www.diffbot.com/">Diffbot</a> who develop a knowledge graph of the WWW. <br/><br/></p>

							
							<h5>Sentiment Analysis</h5>
							<img class="img-responsive" src="./img/tweets.jpg" alt="" width="350" align="right">																				
							<p>Sentiment analysis is the task of automatically assigning a sentiment to a natural language fragment, e.g. a sentence, a tweet or a review. Often sentiment analysis systems distinguish basic categories such as positive, negative, neutral. Our work looks into more fine-grained emotion categories that are motivated from human emotions and that allow us in some cases to make inferences on <a href="publications/Latech2016.pdf">mental states</a> considering correlations and combinations of emotions.</p>											
							
<img class="img-responsive" src="./img/emotions.jpg" alt="" width="350" align="left">								
										
							<p>Current projects include a collaboration with <a href="http://research.ibm.com/labs/uk/">IBM Research</a> on <a href="annika.html">Annika Schoene's</a> PhD thesis. <br/><br/></p>																					
							<h5>Dialogue systems</h5>							
							<p>Spoken dialogue systems are programs that interact with human users using natural language, including text-based, spoken and other multimodal inputs. Our work on dialogue systems is presented in the <a href="interactive_systems.html">Interactive Systems</a> section. Particular strengths are in spoken and task-oriented dialogue systems and systems for assistive technology.  </p>																												
						</div>

	
	<!-- Portfolio -->
	<div id="projects" class="section md-padding">

		<!-- Container -->
		<div class="container">

			<!-- Row -->
			<div class="row">						
					
				</main>
				<!-- /Main -->


				<!-- Aside -->
				<aside id="aside" class="col-md-3">


					<!-- Category -->
					<div class="widget">
						<h3 class="title">Category</h3>
						<div class="widget-category">
							<a href="deep_learning.html#main">Deep Learning</a>
							<a href="evolutionary_algorithms.html#main">Evolutionary Algorithms</a>
							<a href="interactive_systems.html#main">Interactive Systems</a>
							<a href="nlp.html#main">Natural Language Processing</a>
							<a href="bio_health.html#main">Biology and Health</a>
							<a href="natural.html#main">Data and Natural World</a>							
						</div>
					</div>
					<!-- /Category -->

					<!-- Posts sidebar -->
					<div class="widget">
						<h3 class="title">News Stuff</h3>
						
						<!-- single post -->
						<div class="widget-post">
							<a href="https://nips.cc/">
								<img src="./img/neurips2019-post.jpeg" alt="">NeurIPS in Vancouver</a>
							<ul class="blog-meta">
								<li>Dec 2019</li>
							</ul>
						</div>
						<!-- /single post -->

						<!-- single post -->
						<div class="widget-post">
							<a href="https://thespencergroup.co.uk/">
								<img src="./img/rnnc2-post.jpg" alt="">KTP project with Spencer Group</a>
							<ul class="blog-meta">
								<li>Oct 2019</li>
							</ul>
						</div>
						<!-- /single post -->

						<!-- single post -->
						<div class="widget-post">
							<a href="https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A6596404880460611584/?midToken=AQHBPjnIWTOZbg&trk=eml-email_notification_single_mentioned_you_in_this_01-notifications-1-hero%7Ecard%7Efeed&trkEmail=eml-email_notification_single_mentioned_you_in_this_01-notifications-1-hero%7Ecard%7Efeed-null-522tij%7Ek2ho9beq%7Er5-null-voyagerOffline">
								<img src="./img/hackathon-glasgow-post.jpeg" alt=""> Offshore Wind Hackathon, Glasgow</a>
							<ul class="blog-meta">
								<li>Oct 2019</li>
							</ul>
						</div>
						<!-- /single post -->

						<!-- single post -->
						<div class="widget-post">
							<a href="http://auracdt.hull.ac.uk/">
								<img src="./img/cdt-post.jpg" alt=""> Aura Centre for Doctoral Training in Offshore Wind
							and the Environment</a>
							<ul class="blog-meta">
								<li>4 Feb 2019</li>
							</ul>
						</div>
						<!-- /single post -->

						<!-- single post -->
						<div class="widget-post">
							<a href="https://www.eventbrite.com/e/gpu-programming-for-deep-learning-tickets-53947006950">
								<img src="./img/rnnc2-post.jpg" alt=""> GPU programming for deep learning - 24/25 Jan.
							</a>
							<ul class="blog-meta">
								<li>20 Dec 2018</li>
							</ul>
						</div>
						<!-- /single post -->

					<!-- single post -->
						<div class="widget-post">
							<a href="news-xmas-2018.html">
								<img src="./img/xmas-2018-post.jpg" alt=""> Christmas Poster Workshop 2018
							</a>
							<ul class="blog-meta">
								<li>7 Dec 2018</li>
							</ul>
						</div>
						<!-- /single post -->	

						<!-- single post -->
						<div class="widget-post">
							<a href="news-catapult-joyjit-2018.html">
								<img src="./img/catapult-post.jpg" alt=""> OREC Catapult in Glasgow
							</a>
							<ul class="blog-meta">
								<li>22 Nov 2018</li>
							</ul>
						</div>
						<!-- /single post -->
						

						<a href="index.html#news"> --- ALL NEWS --- </a>																		

					</div>
					<!-- /Posts sidebar -->

				</aside>
				<!-- /Aside -->

			</div>
			<!-- /Row -->

		</div>
		<!-- /Container -->

	</div>
	<!-- /Blog -->
		
	
	<!-- Portfolio -->
	<div id="publications" class="section md-padding bg-grey">

		<!-- Container -->
		<div class="container">

			<!-- Row -->
			<div class="row">

				<!-- Section header -->
				<div class="section-header text-center">
					<h2 class="title">Natural Language Processing Publications</h2>
				</div>

			<main class="section ">
					<div class="blog">
									
					
						<!-- publication entry -->
											

						<div class="blog-content">
							<h3>Natural Language Generation for Operations and Maintenance in Wind Turbines.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="joyjit.html">Chatterjee, J.</a>
								</li>							
							<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>									
								<li>
								<a href="https://www.climatechange.ai/CameraReadySubmissions%202-119/22/CameraReadySubmission/neurips_2019.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>	 
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Wind energy is one of the fastest-growing sustainable energy sources in the world
but relies crucially on efficient and effective operations and maintenance to generate
sufficient amounts of energy and reduce downtime of wind turbines and associated
costs. Machine learning has been applied to fault prediction in wind turbines,
but these predictions have not been supported with suggestions on how to avert
and fix faults. We present a data-to-text generation system using transformers to
produce event descriptions from SCADA data capturing the operational status of
turbines and proposing maintenance strategies. Experiments show that our model
learns feature representations that correspond to expert judgements. In making a
contribution to the reliability of wind energy, we hope to encourage organisations
to switch to sustainable energy sources and help combat climate change.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2019. In NeurIPS 2019 Workshop on Tackling Climate Change with Machine Learning. Vancouver, Canada.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
								<a href="natural.html#publications">
									<i class="fa fa-tag"></i>Data and Natural World</a>									
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->					

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Hybrid approaches to fine-grained emotion detection in social media data.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>							
								<li>
								<a href="publications/annika_aaai2020_dc.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>	 
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										This paper states the challenges in fine-grained target-
dependent Sentiment Analysis for social media data using recurrent neural networks. Firstly, we outline the problem statement and give a brief overview of related work in the area. Then we outline progress and results achieved to date, a brief
research plan and future directions of this work.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>To appear. In AAAI-2020 Doctoral Consortium. New York, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Bidirectional Dilated LSTM with Attention for Fine-grained Emotion Classification in Tweets.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>							
								<li>
									<i class="fa fa-user"></i>
									<a href="alex.html">Turner, A.</a>
								</li>									
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
								<!--	<a href="https://aiforsocialgood.github.io/neurips2019/accepted/track1/pdfs/45_aisg_neurips2019.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>	 -->
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We propose a novel approach for fine-grained emotion classification in tweets using a Bidirectional Dilated LSTM (BiDLSTM) with attention. Conventional LSTM architectures can face problems when classifying long sequences, which is problematic for tweets, where
crucial information is often attached to the end of a sequence, e.g. an emoticon. We show that by adding a bidirectional layer, dilations and attention mechanism to a standard LSTM, our model overcomes these problems and is able to maintain complex data
dependencies over time. We present experiments with two datasets,
the 2018 WASSA Implicit Emotions Shared Task and a new dataset
of 240,000 tweets. Our BiDLSTM with attention achieves a test
accuracy of up to 81.97% outperforming competitive baselines by
up to 10.52% on both datasets. Finally, we evaluate our data against
a human benchmark on the same task.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>To appear. In Proceedings of AAAI-2020 Workshop on Affective Content Analysis. New York, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Dilated LSTM with ranked units for classification of suicide notes.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>			
					<li>
									<i class="fa fa-user"></i>
									<a href="alex.html">Turner, A.</a>
								</li>								 				
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="https://aiforsocialgood.github.io/neurips2019/accepted/track1/pdfs/45_aisg_neurips2019.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>	
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Recent statistics in suicide prevention show that people are increasingly posting
their last words online and with the unprecedented availability of textual data
from social media platforms researchers have the opportunity to analyse such data.
Furthermore, psychological studies have shown that our state of mind can manifest
itself in the linguistic features we use to communicate. In this paper, we investigate
whether it is possible to automatically identify suicide notes from other types of
social media blogs in a document-level classification task. Also, we present a
learning model for modelling long sequences, achieving an f1-score of 0.84 over
the baselines of 0.53 and 0.80 (best competing model). Finally, we also show
through visualisations which features the learning model identifies.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2019. In AI for Social Good workshop at NeurIPS (2019), Vancouver, Canada.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
								<a href="bio_health.html#publications">
									<i class="fa fa-tag"></i>Biology and Health</a>									
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Dilated LSTM with attention for Classification of suicide notes.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>
					<li>
									<i class="fa fa-user"></i>
									<a href="george.html">Lacey, G.</a>
								</li>				
					<li>
									<i class="fa fa-user"></i>
									<a href="alex.html">Turner, A.</a>
								</li>								 				
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="https://www.aclweb.org/anthology/D19-6217.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>	
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										In this paper we present a dilated LSTM with
attention mechanism for document-level classification of suicide notes, last statements and
depressed notes. We achieve an accuracy of
87.34% compared to competitive baselines of
80.35% (Logistic Model Tree) and 82.27%
(Bi-directional LSTM with Attention). Furthermore, we provide an analysis of both the
grammatical and thematic content of suicide
notes, last statements and depressed notes. We
find that the use of personal pronouns, cognitive processes and references to loved ones are
most important. Finally, we show through visualisations of attention weights that the Dilated LSTM with attention is able to identify
the same distinguishing features across documents as the linguistic analysis.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2019. In Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019). Hong Kong.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
								<a href="bio_health.html#publications">
									<i class="fa fa-tag"></i>Biology and Health</a>										
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->
						


		<div class="blog-content">
							<h3>Cross-dialectal speech processing</h3>
							<ul class="blog-meta">
							<li>
									<i class="fa fa-user"></i>Whettam, D.</li>
								</li>							
								<li>
									<i class="fa fa-user"></i>Gargett, A.</li>
								</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>								
<!--						<a href="publications/lacey-cec2019.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>									-->
							</ul>
							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										
Despite advances in technology, language diversity remains a challenge to the speech processing community, but there is also an opportunity to rise to this challenge through research and innovation. Pluricentric languages play an important role in such work, particularly where these languages are better resourced. Dedicated researchers across several decades, have steadily contributed resources for some language varieties, increasing general availability of a range of data archives...
										</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2019. INTERSPEECH Satellite Workshop on Pluricentric Languages in Speech Technology, Graz, Austria.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Unsupervised suicide note classification.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/wisdom2018schoene.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>		
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										With the greater availability of linguistic data from public social media platforms and the advancements of natural language processing, a number of opportunities have arisen for researchers to analyse this type of data. Research efforts have mostly focused on detecting the polarity of textual data, evaluating whether there is positive, negative or sometimes neutral content. Especially the use of neural networks has recently yielded significant results in polarity detection experiments. In this paper we present a more fine-grained approach to detecting sentiment in textual data, particularly analysing a corpus of suicide notes, depressive notes and love notes. We achieve a classification accuracy of 71.76% when classifying based on text and sentiment features, and an accuracy of 69.41% when using the words present in the notes alone. We discover that while emotions in all three datasets overlap, each of them has a unique ‘emotion profile’ which allows us to draw conclusions about the potential mental state that is reflects. Using the emotion sequences only, we achieve an accuracy of 75.29%. The results from unannotated data, while worse than the other models, nevertheless represent an encouraging step towards being able to flag potentially harmful social media posts online and in real time. We provide a high-level corpus analysis of the data sets in order to demonstrate the grammatical and emotional differences.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2018. In Proceedings of the 7th KDD Workshop on Issues of Sentiment Discovery and Opinion Mining (WISDOM), co-located
									with the Knowledge Discovery and Data Mining (KDD), London, UK.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Domain Transfer for Deep Natural Language Generation from Abstract Meaning Representations.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/ieee_ci_final_draft.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Stochastic natural language generation systems that are trained from labelled datasets are often domain-specific in their annotation and in their mapping from semantic input representations to lexical-syntactic outputs. As a result, learnt models fail to generalize across domains, heavily restricting their usability beyond single applications. In this article, we focus on the problem of domain adaptation for natural language generation. We show how linguistic knowledge from a source domain, for which labelled data is available, can be adapted to a target domain by reusing training data across domains. As a key to this, we propose to employ abstract meaning representations as a common semantic representation across domains. We model natural language generation as a long short- term memory recurrent neural network encoder-decoder, in which one recurrent neural network learns a latent representation of a semantic input, and a second recurrent neural network learns to decode it to a sequence of words. We show that the learnt representations can be transferred across domains and can be leveraged effectively to improve training on new unseen domains. Experiments in three different domains and with six datasets demonstrate that the lexical-syntactic constructions learnt in one domain can be transferred to new domains and achieve up to 75-100% of the performance of in-domain training. This is based on objective metrics such as BLEU and semantic error rate and a subjective human rating study. Training a policy from prior knowledge from a different domain is consistently better than pure in-domain training by up to 10%.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2017. IEEE Computational Intelligence Magazine: Special Issue on Natural Language Generation with Computational Intelligence.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Deep text generation - Using hierarchical decomposition to mitigate the effect of rare data points.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="alex.html">Turner, A.</a>
								</li>
								<li>
									<a href="publications/ldk2017.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Deep learning has recently been adopted for the task of natural language generation (NLG) and shown remarkable results. However, learning can go awry when the input dataset is too small or not well balanced with regards to the examples it contains for various input sequences. This is relevant to naturally occurring datasets such as many that were not prepared for the task of natural language processing but scraped off the web and originally prepared for a different purpose. As a mitigation to the problem of unbalanced training data, we therefore propose to decompose a large natural language dataset into several subsets that “talk about” the same thing. We show that the decomposition helps to focus each learner’s attention during training. Results from a proof-of-concept study show 73% times faster learning over a flat model and better results.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2017. In Proceedings of Language, Data and Knowledge (LDK), Galway, Ireland. Proceedings in: Springer Lecture Notes
									in Computer Science (LNCS).</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="deep_learning.html#publications">
									<i class="fa fa-tag"></i>Deep Learning</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">

							<h3>Natural language-based presentation of cognitive stimulation to people with dementia in assistive technology: a pilot
								study.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Milders, M.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Al-Salkini, T.</li>
								<li>
									<i class="fa fa-user"></i>Douglas, D.</li>
								<li>
									<a href="publications/accepted-informatics-health.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Currently, an estimated 36 million people worldwide are affected by Alzheimer’s disease or related dementias. In the absence of a cure, non-pharmacological interventions, such as cognitive stimulation, which slow down the rate of deterioration can benefit people with dementia and their caregivers. Such interven- tions have shown to improve well-being and slow down the rate of cognitive decline. It has further been shown that cognitive stimulation in interaction with a computer is as effective as with a human. However, the need to operate a computer often repre- sents a difficulty for the elderly and stands in the way of widespread adoption. A possible solution to this obstacle is to provide a spoken natural language interface that allows people with dementia to interact with the cognitive stimulation software in the same way as they would interact with a human caregiver. This makes the assistive technology accessible to users regardless of their technical skills and provides a fully intuitive user experience. This article describes a pilot study that evaluated the feasibility of computer-based cognitive stimulation through a spoken natural language interface. A prototype software was evaluated with 23 users, including healthy elderly people and people with dementia. Feedback was overwhelmingly positive.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2017. Informatics for Health and Social Care.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="bio_health.html#publications">
									<i class="fa fa-tag"></i>Biology and Health</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->



						<!-- publication entry -->

						<div class="blog-content">
							<h3>Extrinsic vs Intrinsic Evaluation of Natural Language Generation for Spoken Dialogue Systems and Social Robotics.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Keizer, S.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<a href="https://www.springer.com/gb/book/9789811025846"><i class="fa fa-external-link"></i></a>Link to book</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										[Book abstract] In the past 10 years, very few published studies include some kind of extrinsic evaluation of an NLG component in an end-to-end-system, be it for phone or mobile-based dialogues or social robotic interaction. This may be attributed to the fact that these types of evaluations are very costly to set-up and run for a single component. The question therefore arises whether there is anything to be gained over and above intrinsic quality measures obtained in off-line experiments? In this article, we describe a case study of evaluating two variants of an NLG surface realiser and show that there are significant differences in both extrinsic measures and intrinsic measures. These differences can be used to inform further iterations of component and system development.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2016. In Jokinen, Kristiina and Wilcock, Graham (eds.) Dialogues with Social Robots – Enablements, Analyses, and
									Evaluation. Berlin: Springer Lecture Notes in Electrical Engineering (LNEE). ISBN 978-981-10-2584-6.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>Automatic Identification of Suicide Notes from Linguistic and Sentiment Features.</h3>

							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="annika.html">Schoene, A.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/Latech2016.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use to communicate. Recent statistics in suicide prevention show that young people are increasingly posting their last words online. In this paper, we investigate whether it is possible to automatically identify suicide notes and discern them from other types of online discourse based on analysis of sentiments and linguistic features. Using supervised learning, we show that our model achieves an accuracy of 86.6%, outperforming previous work on a similar task by over 4%.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2016. In Proceedings of The 10th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities
									(LaTeCH), co-located with ACL-2016. Berlin, Germany.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Information Density and Overlaps in Spoken Dialogue.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Yu, Y.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/csl2016.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Incremental dialogue systems are often perceived as more responsive and natural because they are able to address phenomena of turn-taking and overlapping speech, such as backchannels or barge-ins. Previous work in this area has often identified distinctive prosodic features, or features relating to syntactic or semantic completeness, as marking appropriate places of turn-taking. In a separate strand of work, psycholinguistic studies have established a connection between information density and prominence in language—the less expected a linguistic unit is in a particular context, the more likely it is to be linguistically marked. This has been observed across linguistic levels, including the prosodic, which plays an important role in predicting overlapping speech.
										In this article, we explore the hypothesis that information density (ID) also plays a role in turn-taking. Specifically, we aim to show that humans are sensitive to the peaks and troughs of information density in speech, and that over-lapping speech at ID troughs is perceived as more acceptable than overlaps at ID peaks. To test our hypothesis, we collect human ratings for three models of generating overlapping speech based on features of: (1) prosody and semantic or syntactic completeness, (2) information density, and (3) both types of	information. Results show that over 50% of users preferred the version using both types of features, followed by a preference for information density features alone. This indicates a clear human sensitivity to the effects of information density in spoken language and provides a strong motivation to adopt this metric for the design, development and evaluation of turn-taking modules in spoken and incremental dialogue systems.									
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2016. Computer Speech and Language 37, pp. 82–97.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Why bother? Is evaluation of NLG in an end-to-end Spoken Dialogue System worth it?</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Keizer, S.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<a href="publications/iwsds2016.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										In the past 10 years, only around 15% of published conference papers include some kind of extrinsic evaluation of an NLG component in an end-to-end system. These types of evaluations are costly to set-up and run, so is it worth it? Is there anything to be gained over and above intrinsic quality measures obtained in off-line experiments? In this paper, we describe a case study of evaluating two variants of an NLG surface realiser and show that there are significant differences in both extrinsic measures and intrinsic measures. These significant differences would need to be factored into future iterations of the component and therefore, we con- clude that extrinsic evaluations are worthwhile.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2016. In Proceedings of the International Workshop on Spoken Dialogue Systems (IWSDS). Ivalo, Finland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Hierarchical Reinforcement Learning for Situated Language Generation. </h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="publications/nle2015.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Natural Language Generation systems in interactive settings often face a multitude of choices, given that the communicative effect of each utterance they generate depends crucially on the interplay between its physical circumstances, addressee and interaction history. This is particularly true in interactive and situated settings. In this paper we present a novel approach for situated Natural Language Generation in dialogue that is based on hierarchical reinforcement learning and learns the best utterance for a context by optimisation through trial and error. The model is trained from human–human corpus data and learns particularly to balance the trade-off between efficiency and detail in giving instructions: the user needs to be given sufficient information to execute their task, but without exceeding their cognitive load. We present results from simulation and a task-based human evaluation study comparing two different versions of hierarchical reinforcement learning: One operates using a hierarchy of policies with a large state space and local knowledge, and the other additionally shares knowledge across generation subtasks to enhance performance. Results show that sharing knowledge across subtasks achieves better performance than learning in isolation, leading to smoother and more successful interactions that are better perceived by human users.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2015. Natural Language Engineering 21, pp 391–435. Cambridge University Press. </li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Cluster-Based Prediction of User Ratings for Stylistic Surface Realisation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/eacl2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Surface realisations typically depend on their target style and audience. A challenge in estimating a stylistic realiser from data is that humans vary significantly in their subjective perceptions of linguistic forms and styles, leading to almost no correlation between ratings of the same utterance. We address this problem in two steps. First, we estimate a mapping function between the linguistic features of a corpus of utterances and their human style ratings. Users are partitioned into clusters based on the similarity of their ratings, so that ratings for new utterances can be estimated, even for new, unknown users. In a second step, the estimated model is used to re-rank the outputs of a number of surface realisers to produce stylistically adaptive output. Results confirm that the generated styles are recognisable to human judges and that predictive models based on clusters of users lead to better rating predictions than models based on an average population of users.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL).
									Gothenburg, Sweden. </li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>A Semi-Supervised Clustering Approach for Semantic Slot Labelling.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<a href="publications/icmla2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Work on training semantic slot labellers for use in Natural Language Processing applications has typically either relied on large amounts of labelled input data, or has assumed entirely unlabelled inputs. The former technique tends to be costly to apply, while the latter is often not as accurate as its supervised counterpart. Here, we present a semi-supervised learning approach that automatically labels the semantic slots in a set of training data and aims to strike a balance between the dependence on labelled data and prediction accuracy. The essence of our algorithm is to cluster clauses based on a similarity function that combines lexical and semantic information. We present experiments that compare different similarity functions for both our semi-supervised setting and a fully unsupervised baseline. While semi-supervised learning expectedly outperforms unsupervised learning, our results show that (1) this effect can be observed based on very few training data instances and that increasing the size of the training data does not lead to better performance, and (2) that lexical and semantic information contribute differently in different domains so that clustering based on both types of information offers the best generalisation.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. In Proceedings of the International Conference on Machine Learning and Applications (ICMLA). Detroit, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>Training a Statistical Surface Realiser from Automatic Slot Labelling.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<a href="publications/slt2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Training a statistical surface realiser typically relies on labelled training data or parallel data sets, such as corpora of paraphrases. The procedure for obtaining such data for new domains is not only time-consuming, but it also restricts the incorporation of new semantic slots during an interaction, i.e. using an online learning scenario for automatically extended domains. Here, we present an alternative approach to statistical surface realisation from unlabelled data through automatic semantic slot labelling. The essence of our algorithm is to cluster clauses based on a similarity function that combines lexical and semantic information. Annotations need to be reliable enough to be utilised within a spoken dialogue system. We compare different similarity functions and evaluate our surface realiser—trained from unlabelled data—in a human rating study. Results confirm that a surface realiser trained from automatic slot labels can lead to outputs of comparable quality to outputs trained from human-labelled inputs.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. In Proceedings of the IEEE Workshop on Spoken Language Technology (SLT). South Lake Tahoe, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>The PARLANCE Mobile App for Interactive Search in English and Mandarin.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Aufaure, M.</li>
								<li>
									<i class="fa fa-user"></i>Alexopoulos, P.</li>
								<li>
									<i class="fa fa-user"></i>Bouchard, H.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Gasic, M.</li>
								<li>
									<i class="fa fa-user"></i>Henderson, J.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<i class="fa fa-user"></i>Mika, P.</li>
								<li>
									<i class="fa fa-user"></i>Ben Mustapha, N.</li>
								<li>
									<i class="fa fa-user"></i>Potter, T.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Thomson, B.</li>
								<li>
									<i class="fa fa-user"></i>Tsiakoulis, P.</li>
								<li>
									<i class="fa fa-user"></i>Vanrompay, Y.</li>
								<li>
									<i class="fa fa-user"></i>Villa-Terrazas, B.</li>
								<li>
									<i class="fa fa-user"></i>Yazdani, M.</li>
								<li>
									<i class="fa fa-user"></i>Young, S.</li>
								<li>
									<i class="fa fa-user"></i>Yu, Y.</li>
								<li>
									<a href="publications/sigdial2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We demonstrate a mobile application in English and Mandarin to test and evaluate components of the Parlance dialogue system for interactive search under real-world conditions.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. In Proceedings of the Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGdial).</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>Non-Strict Hierarchical Reinforcement Learning for Interactive Systems and Robots.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Kruijff-Korbayová, I.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/acm-tiis2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>	
									Conversational systems and robots that use reinforcement learning for policy optimization in large domains often face the problem of limited scalability. This problem has been addressed either by using function approximation techniques that estimate the approximate true value function of a policy or by using a hierarchical decomposition of a learning task into subtasks. We present a novel approach for dialogue policy optimization that combines the benefits of both hierarchical control and function approximation and that allows flexible transitions between dialogue subtasks to give human users more control over the dialogue. To this end, each reinforcement learning agent in the hierarchy is extended with a subtask transition function and a dynamic state space to allow flexible switching between subdialogues. In addition, the subtask policies are represented with linear function approximation in order to generalize the decision making to situations unseen in training. Our proposed approach is evaluated in an interactive conversational robot that learns to play quiz games. Experimental results, using simulation and real users, provide evidence that our proposed approach can lead to more flexible (natural) interactions than strict hierarchical control and that it is preferred by human users.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. ACM Transactions on Interactive Intelligent Systems. Vol. 4, No. 4. </li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>Context-Sensitive Natural Language Generation: From Knowledge-Driven to Data-Driven Techniques. </h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/compass2014.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Context-sensitive Natural Language Generation is concerned with the automatic generation of system output that is in several ways adaptive to its target audience or the situational circumstances of its production. In this article, I will provide an overview of the most popular methods that have been applied to context-sensitive generation. A particular focus will be on the shift from knowledge-driven to data- driven approaches that has been witnessed in the last decade. While this shift has offered powerful new methods for large-scale adaptivity and flexible output generation, purely data-driven approaches still struggle to reach the linguistic depth of their knowledge-driven predecessors. Bridging the gap between both types of approaches is therefore an important future research direction.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. Language and Linguistics Compass, Vol. 8(3), pp. 99–115.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">

							<h3>A Joint Learning Approach for Situated Language Generation. </h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="https://www.cambridge.org/core/books/natural-language-generation-in-interactive-systems/BC5CC3B56A6BA4A57576BAC06136D26A"><i class="fa fa-external-link"></i></a>Link to book</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
									[Book abstract] An informative and comprehensive overview of the state-of-the-art in natural language generation (NLG) for interactive systems, this guide serves to introduce graduate students and new researchers to the field of natural language processing and artificial intelligence, while inspiring them with ideas for future research. Detailing the techniques and challenges of NLG for interactive applications, it focuses on the research into systems that model collaborativity and uncertainty, are capable of being scaled incrementally, and can engage with the user effectively. A range of real-world case studies is also included. The book and the accompanying website feature a comprehensive bibliography, and refer the reader to corpora, data, software and other resources for pursuing research on natural language generation and interactive systems, including dialog systems, multimodal interfaces and assistive technologies. It is an ideal resource for students and researchers in computational linguistics, natural language processing and related fields.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. In Amanda Stent and Srinivas Bangalore (eds.) Natural Language Generation in Interactive Systems. Cambridge
									University Press.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Getting to Know Users: Accounting for the Variability in User Ratings.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/semdial2014-eval.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Evaluations of dialogue systems and language generators often rely on subjective user ratings to assess output quality and performance. Humans however vary in their preferences so that estimating an accurate prediction model is difficult. Using a method that clusters utterances based on their linguistic features and ratings (Dethlefs et al., 2014), we discuss the possibility of obtaining user feedback implicitly during an interaction. This approach promises better predictions of user preferences through continuous re-estimation.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. Poster paper in the Workshop on the Semantics and Pragmatics of Dialogue (SemDial). Edinburgh, Scotland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Two Alternative Frameworks for Deploying Spoken Dialogue Systems to Mobile Platforms for Evaluation “in the Wild”.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Aufaure, M.</li>
								<li>
									<i class="fa fa-user"></i>Alexopoulos, P.</li>
								<li>
									<i class="fa fa-user"></i>Bouchard, H.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Gasic, M.</li>
								<li>
									<i class="fa fa-user"></i>Henderson, J.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<i class="fa fa-user"></i>Mika, P.</li>
								<li>
									<i class="fa fa-user"></i>Potter, T.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Tsiakoulis, P.</li>
								<li>
									<i class="fa fa-user"></i>Vanrompay, Y.</li>
								<li>
									<i class="fa fa-user"></i>Villa-Terrazas, B.</li>
								<li>
									<i class="fa fa-user"></i>Yazdani, M.</li>
								<li>
									<i class="fa fa-user"></i>Young, S.</li>
								<li>
									<i class="fa fa-user"></i>Yu, Y.</li>
								<li>
									<a href="publications/semdial2014-app.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>	
									We demonstrate two alternative frameworks for testing and evaluating spoken dialogue systems on mobile devices for use “in the wild”. We firstly present a spoken dialogue system that uses third party ASR (Automatic Speech Recognition) and TTS (Text-To-Speech) components and then present an alternative using audio compression to allow for entire systems with home-grown ASR/TTS to be plugged in directly. Some advantages and drawbacks of both are discussed.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2014. Poster paper in the Workshop on the Semantics and Pragmatics of Dialogue (SemDial). Edinburgh, Scotland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Conditional Random Fields for Responsive Surface Realisation Using Global Features.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/acl2013.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Surface realisers in spoken dialogue systems need to be more responsive than conventional surface realisers. They need to be sensitive to the utterance context as well as robust to partial or changing generator inputs. We formulate surface realisation as a sequence labelling task and combine the use of conditional random fields (CRFs) with semantic trees. Due to their extended notion of context, CRFs are able to take the global utterance context into account and are less constrained by local features than other realisers. This leads to more natural and less repetitive surface realisation. It also allows generation from partial and modified inputs and is therefore applicable to incremental surface realisation. Results from a human rating study confirm that users are sensitive to this extended notion of context and assign ratings that are significantly higher (up to 14%) than those for taking only local context into account.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL). Sofia, Bulgaria.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Hierarchical Joint Learning for Natural Language Generation. </h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="https://www.iospress.nl/book/hierarchical-joint-learning-for-natural-language-generation/"><i class="fa fa-external-link"></i></a>Link to book</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
									</summary>
										Natural Language Generation (NLG) systems typically face an uncertainty regarding the best utterance to communicate to a user in a given context given that the effect of a single utterance depends crucially on the interplay between its physical environment, pragmatic circumstances, addressee and interaction history. NLG system designers have traditionally used a pipeline architecture to divide the generation process into the distinct stages of content selection, utterance planning and surface realisation to choose the semantics, organisation and realisation of an utterance. Unfortunately, this sequential model does not account for the interdependencies that exist among these stages, which in practice has been manifest in inefficient instruction giving and an increased cognitive load for the user. 
										This thesis will advocate a joint optimisation framework for situated NLG that is based on Hierarchical Reinforcement Learning combined with graphical models and will learn the best utterance for a given context by optimising its behaviour through a trial and error search. The joint model considers decisions at different NLG stages in interdependence with each other and thereby produces more context-sensitive utterances than is possible when considering decisions in isolation. To enhance the human-likeness of the model, two augmentations will be made. We will introduce the notion of a Hierarchical Information State to support the systematic pre-specification of prior knowledge and human preferences for content selection. Graphical models—Hidden Markov Models and Bayesian Networks—will then be integrated as generation spaces to encourage natural surface realisation by balancing the proportion of alignment and variation.
										Results from a human evaluation study show that the hierarchical learning agent learns a robust generation policy that adapts to new circumstances and users flexibly leading to smooth and successful interactions. In terms of the comparison between a joint and an isolated optimisation, results indicate that a jointly optimised system achieves higher user satisfaction and task success and is better perceived by human users than its isolated counterpart. To demonstrate the domain-independence and generalisabilty of the hierarchical joint optimisation framework, an additional study will be presented that transfers the model to a new, but related, domain: the generation of route instructions in a real navigation scenario using a situated dialogue system for indoor navigation. Results confirm that the NLG policy can be applied to new domains with limited effort and contribute to high task success and user satisfaction.										
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. IOS Press / AKA Publishing. In Series Dissertations on Artificial Intelligence, Volume 340. ISBN 978-1-61499-115-1.
									Amsterdam / Berlin.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Hierarchical Joint Learning for Natural Language Generation. </h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/nd-thesis2013.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Natural Language Generation (NLG) systems typically face an uncertainty regarding the best utterance to communicate to a user in a given context given that the effect of a single utterance depends crucially on the interplay between its physical environment, pragmatic circumstances, addressee and interaction history. NLG system designers have traditionally used a pipeline architecture to divide the generation process into the distinct stages of content selection, utterance planning and surface realisation to choose the semantics, organisation and realisation of an utterance. Unfortunately, this sequential model does not account for the interdependencies that exist among these stages, which in practice has been manifest in inefficient instruction giving and an increased cognitive load for the user. 
										This thesis will advocate a joint optimisation framework for situated NLG that is based on Hierarchical Reinforcement Learning combined with graphical models and will learn the best utterance for a given context by optimising its behaviour through a trial and error search. The joint model considers decisions at different NLG stages in interdependence with each other and thereby produces more context-sensitive utterances than is possible when considering decisions in isolation. To enhance the human-likeness of the model, two augmentations will be made. We will introduce the notion of a Hierarchical Information State to support the systematic pre-specification of prior knowledge and human preferences for content selection. Graphical models—Hidden Markov Models and Bayesian Networks—will then be integrated as generation spaces to encourage natural surface realisation by balancing the proportion of alignment and variation.
										Results from a human evaluation study show that the hierarchical learning agent learns a robust generation policy that adapts to new circumstances and users flexibly leading to smooth and successful interactions. In terms of the comparison between a joint and an isolated optimisation, results indicate that a jointly optimised system achieves higher user satisfaction and task success and is better perceived by human users than its isolated counterpart. To demonstrate the domain-independence and generalisabilty of the hierarchical joint optimisation framework, an additional study will be presented that transfers the model to a new, but related, domain: the generation of route instructions in a real navigation scenario using a situated dialogue system for indoor navigation. Results confirm that the NLG policy can be applied to new domains with limited effort and contribute to high task success and user satisfaction.										
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. PhD Thesis. University of Bremen, Faculty of Linguistics, Germany.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<div class="blog-content">
							<h3>Impact of ASR N-Best Information on Bayesian Dialogue Act Recognition.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/sigdial2013.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										A challenge in dialogue act recognition is the mapping from noisy user inputs to dialogue acts. In this paper we describe an approach for re-ranking dialogue act hypotheses based on Bayesian classifiers that incorporate dialogue history and Automatic Speech Recognition (ASR) N-best information. We report results based on the Let’s Go dialogue corpora that show (1) that including ASR N-best information results in improved dialogue act recognition performance (+7% accuracy), and (2) that competitive results can be obtained from as early as the first system dialogue act, reducing the need to wait for subsequent system dialogue acts.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. In Proceedings of the 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGdial).
									Metz, France.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Proceedings of the Young Researcher’s Roundtable on Spoken Dialogue Systems.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>El Asri, L.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Henderson, M.</li>
								<li>
									<i class="fa fa-user"></i>Kennington, C.</li>
								<li>
									<i class="fa fa-user"></i>Mitchell, C.</li>
								<li>
									<i class="fa fa-user"></i>Schütte, N.</li>
								<li>
									<i class="fa fa-user"></i>Villalba, M.</li>
								<li>
									<i class="fa fa-user"></i>Baheux, D.</li>
								<li>
									<a href="publications/yrrsds2013.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We are delighted to welcome you to the Ninth Young Researchers’ Roundtable on Spoken Dialogue Systems in Metz, France. YRRSDS is a yearly event that began in 2005 in Lisbon, followed by Pittsburgh, Antwerp, Columbus, London, Tokyo, Portland, and Seoul. The aim of the workshop is to promote the networking of students, post docs, and junior researchers working in research related to spoken dialogue systems in academia and industry. The workshop provides an open forum where participants can discuss their research interests, current work, and future plans.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. Co-located with the 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGdial).
									Metz, France.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">

							<h3>Barge-in Effects in Bayesian Dialogue Act Recognition and Simulation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/asru2013.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Dialogue act recognition and simulation are traditionally considered separate processes. Here, we argue that both can be fruitfully treated as interleaved processes within the same probabilistic model, leading to a synchronous improvement of performance in both. To demonstrate this, we train multiple Bayes Nets that predict the timing and content of the next user utterance. A specific focus is on providing support for barge-ins. We describe experiments using the Let’s Go data that show an improvement in classification accuracy (+5%) in Bayesian dialogue act recognition involving barge-ins using partial context compared to using full context. Our results also indicate that simulated dialogues with user barge-in are more realistic than simulations without barge-in events.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), Olomouc, Czech Republic.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Demonstration of the PARLANCE System: A Data-Driven, Incremental, Spoken Dialogue System for Interactive Search.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Aufaure, M.</li>
								<li>
									<i class="fa fa-user"></i>Alexopoulos, P.</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Gasic, M.</li>
								<li>
									<i class="fa fa-user"></i>Henderson, J.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<i class="fa fa-user"></i>Liu, X.</li>
								<li>
									<i class="fa fa-user"></i>Mika, P.</li>
								<li>
									<i class="fa fa-user"></i>Mustapha, N.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Thomson, B.</li>
								<li>
									<i class="fa fa-user"></i>Tsiakoulis, P.</li>
								<li>
									<i class="fa fa-user"></i>Vanrompay, Y.</li>
								<li>
									<i class="fa fa-user"></i>Villazon-Terrazas, B.</li>
								<li>
									<i class="fa fa-user"></i>Young, S.</li>
								<li>
									<a href="publications/sigdial2013-demo.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										The Parlance system for interactive search processes dialogue at a micro-turn level, displaying dialogue phenomena that play a vital role in human spoken conversation. These dialogue phenomena include more natural turn-taking through rapid system responses, generation of backchannels, and user barge-ins. The Parlance demonstration system differentiates from other incremental systems in that it is data-driven with an infrastructure that scales well.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2013. In Proceedings of the 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGdial).
									Metz, France. </li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/emnlp2012.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Abstract
									Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are not sensitive to ID by more than 23%.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-CoNLL). Jeju, South
									Korea.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Optimising Incremental Generation for Spoken Dialogue Systems: Reducing the Need for Fillers.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/inlg2012.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Recent studies have shown that incremental systems are perceived as more reactive, natural, and easier to use than non-incremental systems. However, previous work on incremental NLG has not employed recent advances in statistical optimisation using machine learning. This paper combines the two approaches, showing how the update, revoke and purge operations typically used in incremental approaches can be implemented as state transitions in a Markov Decision Process. We design a model of incremental NLG that generates output based on micro-turn interpretations of the user’s utterances and is able to optimise its decisions using statistical machine learning. We present a proof-of-concept study in the domain of Information Presentation (IP), where a learning agent faces the trade-off of whether to present information as soon as it is available (for high reactiveness) or else to wait until input ASR hypotheses are more reliable. Results show that the agent learns to avoid long waiting times, fillers and self-corrections, by re-ordering content based on its confidence.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. In Proceedings of the 7th International Conference on Natural Language Generation (INLG). Chicago, IL, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Comparing HMMs and Bayesian Networks for Surface Realisation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="publications/naacl2012.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>			
							Natural Language Generation (NLG) systems often use a pipeline architecture for sequential decision making. Recent studies however have shown that treating NLG decisions jointly rather than in isolation can improve the overall performance of systems. We present a joint learning framework based on Hierarchical Reinforcement Learning (HRL) which uses graphical models for surface realisation. Our focus will be on a comparison of Bayesian Networks and HMMs in terms of user satisfaction and naturalness. While the former perform best in isolation, the latter present a scalable alternative within joint systems.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. In Proceedings of the 12th Conference of the North American Chapter of the Association for Computational Linguistics
									(NAACL-HLT). Montréal, Canada.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->



						<!-- publication entry -->

						<div class="blog-content">
							<h3>Dialogue Systems Using Online Learning: Beyond Empirical Methods.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/sdctd2012-online.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We discuss a change of perspective for training dialogue systems, which requires a shift from traditional empirical methods to online learning methods. We motivate the application of online learning, which provides the benefit of improving the system’s behaviour continuously often after each turn or dialogue rather than after hundreds of dialogues. We describe the requirements and advances for dialogue systems with online learning, and speculate on the future of these kinds of systems.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. In Proceedings of the Workshop on Future Directions and Needs in the Spoken Dialogue Community: Tools and Data
									(SDCTD). Co-located with NAACL-HLT. Montréal, Canada.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Incremental Spoken Dialogue Systems: Tools and Data.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/sdctd2012-incremental.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Strict-turn taking models of dialogue do not accurately model human incremental processing, where users can process partial input and plan partial utterances in parallel. We discuss the current state of the art in incremental systems and propose tools and data required for further advances in the field of Incremental Spoken Dialogue Systems.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. In Proceedings of the Workshop on Future Directions and Needs in the Spoken Dialogue Community: Tools and Data
									(SDCTD). Co-located with NAACL-HLT. Montréal, Canada.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Optimising Incremental Generation for Information Presentation of Mobile Search Results.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Hastie, H.</li>
								<li>
									<i class="fa fa-user"></i>Rieser, V.</li>
								<li>
									<i class="fa fa-user"></i>Lemon, O.</li>
								<li>
									<a href="publications/sipi2012.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										This abstract discusses a proof-of-concept study in incremental Natural Language Generation (NLG) in the domain of Information Presentation for Spoken Dialogue Systems. The work presented is part of the FP7 EC Parlance project (http://www.parlance- project.eu). The goal of Parlance is to develop personalised, mobile, interactive, hyper-local search through speech. Recent trends in Information Retrieval are towards incremental, interactive search and we argue that spoken dialogue systems can provide a truly natural medium for this type of interactive search. This is particularly attractive for people on the move, who have their hands and eyes busy.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2012. Presentation at Symposium: Influencing People with Information (SIPI). Aberdeen, Scotland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Spatially-Aware Dialogue Control Using Hierarchical Reinforcement Learning.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/acm2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										This article addresses the problem of scalable optimization for spatially-aware dialogue systems. These kinds of systems must perceive, reason, and act about the spatial environment where they are embedded. We formulate the problem in terms of Semi-Markov Decision Processes and propose a hierarchical reinforcement learning approach to optimize subbehaviors rather than full behaviors. Because of the vast number of policies that are required to control the interaction in a dynamic environment (e.g., a dialogue system assisting a user to navigate in a building from one location to another), our learning approach is based on two stages: (a) the first stage learns low-level behavior, in advance; and (b) the second stage learns high-level behavior, in real time. For such a purpose we extend an existing algorithm in the literature of reinforcement learning in order to support reusable policies and therefore to perform fast learning. We argue that our learning approach makes the problem feasible, and we report on a novel reinforcement learning dialogue system that performs a joint optimization between dialogue and spatial behaviors. Our experiments, using simulated and real environments, are based on a text-based dialogue system for indoor navigation. Experimental results in a realistic environment reported an overall user satisfaction result of 89%, which suggests that our proposed approach is attractive for its application in real interactions as it combines fast learning with adaptive and reasonable behavior.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. ACM Transactions on Speech and Language Processing (Special Issue on Machine Learning for Robust and Adaptive
									Spoken Dialogue Systems). Vol. 7, No. 3, pp. 1-26.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">

							<h3>Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="publications/acl2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Surface realisation decisions in language generation can be sensitive to a language model, but also to decisions of content selection. We therefore propose the joint optimisation of content selection and surface realisation using Hierarchical Reinforcement Learning (HRL). To this end, we suggest a novel reward function that is induced from human data and is especially suited for surface realisation. It is based on a generation space in the form of a Hidden Markov Model (HMM). Results in terms of task success and human-likeness suggest that our unified approach performs better than greedy or random baselines.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. In Proceedings of the 49th Annual Conference of the Association for Computational Linguistics (ACL-HLT). Short
									Papers. Portland, OR, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Optimizing Situated Dialogue Management in Unknown Environments.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/interspeech2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We present a conversational learning agent that helps users navigate through complex and challenging spatial environments. The agent exhibits adaptive behaviour by learning spatially-aware dialogue actions while the user carries out the navigation task. To this end, we use Hierarchical Reinforcement Learning with relational representations to efficiently optimize dialogue actions tightly-coupled with spatial ones, and Bayesian networks to model the user’s beliefs of the navigation environment. Since these beliefs are continuously changing, we induce the agent’s behaviour in real time. Experimental results, using simulation, are encouraging by showing efficient adaptation to the user’s navigation knowledge, specifically to the generated route and the intermediate locations to negotiate with the user.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. In Proceedings of INTERSPEECH. Florence, Italy.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Optimising Natural Language Generation Decision Making for Situated Dialogue.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Viethen, J.</li>
								<li>
									<a href="publications/sigdial2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										Natural language generators are faced with a multitude of different decisions during their generation process. We address the joint optimisation of navigation strategies and referring expressions in a situated setting with respect to task success and human-likeness. To this end, we present a novel, comprehensive framework that combines supervised learning, Hierarchical Reinforcement Learning and a hierarchical Information State. A human evaluation shows that our learnt instructions are rated similar to human instructions, and significantly better than the supervised learning baseline.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. In Proceedings of the 12th Annual Meeting on Discourse and Dialogue (SIGdial). Portland, OR, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Combining Hierarchical Reinforcement Learning and Bayesian Networks for Natural Language Generation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="publications/enlg2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>			
									Language generators in situated domains face a number of content selection, utterance planning and surface realisation decisions, which can be strictly interdependent. We therefore propose to optimise these processes in a joint fashion using Hierarchical Reinforcement Learning. To this end, we induce a reward function for content selection and utterance planning from data using the PARADISE framework, and suggest a novel method for inducing a reward function for surface realisation from corpora. It is based on generation spaces represented as Bayesian Networks. Results in terms of task success and human-likeness suggest that our unified approach performs better than a baseline optimised in isolation or a greedy or random baseline. It receives human ratings close to human authors.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. In Proceedings of the 13th European Workshop on Natural Language Generation (ENLG). Nancy, France.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>The Bremen System for the GIVE-2.5 Challenge.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/enlg2011-give.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>
							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										This paper presents the Bremen system for the GIVE-2.5 challenge. It is based on decision trees learnt from new annotations of the GIVE corpus augmented with manually specified rules. Surface realisation is based on context-free grammars. The paper will address advantages and shortcomings of the approach and discuss how the present system can serve as a baseline for a future evaluation with an improved version using hierarchical reinforcement learning with graphical models.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. In Proceedings of the 13th European Workshop on Natural Language Generation (ENLG). Generation Challenges Session.
									Nancy, France.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Position Paper in the Young Researchers’ Roundtable on Spoken Dialogue Systems (YRRSDS).</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/yrrsds2011.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										My research interests involve context-sensitive, or adaptive, Natural Language Generation (NLG) for situated dialogue systems, especially for spoken interaction. Context-sensitive situated dialogue systems are typically required to adapt flexibly to dynamic changes of (a) properties of the situation or the spatial setting, such as visible objects, or the complexity of the environment, (b) properties of the user, such as their prior knowledge, goals, beliefs, and general information need, and (c) the dialogue history. In this context, I am mainly interested in applying Reinforcement Learning (RL) with hierarchical control and prior knowledge in several contexts of rather large-scale systems for complex domains. I have also recently looked into the joint optimisation of different system behaviours for interdependent decision making between them.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2011. Portland, OR, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>Hierarchical Reinforcement Learning for Adaptive Text Generation.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<a href="publications/inlg2010.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>
							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>	
									We present a novel approach to natural language generation (NLG) that applies hierarchical reinforcement learning to text generation in the wayfinding domain. Our approach aims to optimise the integration of NLG tasks that are inherently different in nature, such as decisions of content selection, text structure, user modelling, referring expression generation (REG), and surface realisation. It also aims to capture existing interdependencies between these areas. We apply hierarchical reinforcement learning to learn a generation policy that captures these interdependencies, and that can be transferred to other NLG tasks. Our experimental results—in a simulated environment—show that the learnt wayfinding policy outperforms a baseline policy that takes reasonable actions but without optimization.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. In Proceedings of the 6th International Conference on Natural Language Generation (INLG). Dublin, Ireland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Route Instructions in Map-Based and Human-Based Dialogue: A Comparative Analysis.</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Tenbrink, T.</li>
								<li>
									<i class="fa fa-user"></i>Ross, R.</li>
								<li>
									<i class="fa fa-user"></i>Thomas, K.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Andonova, E.</li>
								<li>
									<a href="https://www.sciencedirect.com/science/article/pii/S1045926X10000315"><i class="fa fa-external-link"></i></a>Link to article</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										When conveying information about spatial situations and goals, speakers adapt flexibly to their addressee in order to reach the communicative goal efficiently and effortlessly. Our aim is to equip a dialogue system with the abilities required for such a natural, adaptive dialogue. In this paper we investigate the strategies people use to convey route information in relation to a map by presenting two parallel studies involving human–human and human–computer interaction. We compare the instructions given to a human interaction partner with those given to a dialogue system which reacts by basic verbal responses and dynamic visualization of the route in the map. The language produced by human route givers is analyzed with respect to a range of communicative as well as cognitively crucial features, particularly perspective choice and references to locations across levels of granularity. Results reveal that speakers produce systematically different instructions with respect to these features, depending on the nature of the interaction partner, human or dialogue system. Our further analysis of clarification and reference resolution strategies produced by human route followers provides insights into dialogue strategies that future systems should be equipped with.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. Journal of Visual Languages and Computing. Vol. 21, No. 5, pp. 292-309.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Evaluating Task Success in a Dialogue System for Indoor Navigation</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>Richter, K.-F.</li>
								<li>
									<i class="fa fa-user"></i>Andonova, E.</li>
								<li>
									<i class="fa fa-user"></i>Bateman, J.</li>
								<li>
									<a href="publications/semdial2010.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										In this paper we address the assessment of dialogue systems for indoor wayfinding. Based on the PARADISE evaluation framework we propose and evaluate several task success metrics for such a purpose. According to correlation and multiple linear regression analyses, we found that task success metrics that penalise difficulty in wayfinding are more informative of system performance than a success/failure binary task success metric.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. In Proceedings of the 14th Workshop on the Semantics and Pragmatics of Dialogue (SemDial-PozDial). Poznan,
									Poland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>Generating Adaptive Route Instructions Using Hierarchical Reinforcement Learning</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Frommberger, L.</li>
								<li>
									<i class="fa fa-user"></i>Richter, K.-F.</li>
								<li>
									<i class="fa fa-user"></i>Bateman, J.</li>
								<li>
									<a href="publications/spatialCognition2010.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>

							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We present a learning approach for efficiently inducing adaptive behaviour of route instructions. For such a purpose we propose a two-stage approach to learn a hierarchy of wayfinding strategies using hierarchical reinforcement learning. Whilst the first stage learns low-level behaviour, the second stage focuses on learning high-level behaviour. In our proposed approach, only the latter is to be applied at runtime in user-machine interactions. Our experiments are based on an indoor navigation scenario for a building that is complex to navigate. We compared our approach with flat reinforcement learning and a fully-learnt hierarchical approach. Our experimental results show that our proposed approach learns significantly faster than the baseline approaches. In addition, the learnt behaviour shows to adapt to the type of user and structure of the spatial environment. This approach is attractive to automatic route giving since it combines fast learning with adaptive behaviour.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. In Proceedings of the 7th International Conference on Spatial Cognition **(Spatial Cognition VII)**. Portland,
									OR, USA.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->


						<!-- publication entry -->

						<div class="blog-content">
							<h3>The Dublin-Bremen System for the GIVE2-Challenge</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Schuette, N.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<a href="publications/inlg2010-give.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>
							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>					
					This paper describes the Dublin-Bremen GIVE-2 generation system. Our main approach focused on abstracting over the low-level behaviour of the baseline agent and guide the user by more high-level navigation information. For this purpose, we provided the user with (a) high-level action commands, (b) lookahead information, and (c) a “patience” period after they left the intended path to allow exploration. We describe a number of problems that our system encountered during the evaluation due to some of our initial assumptions not holding, and address several means by which we could achieve better performance in the future.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. Poster presentation at the 6th International Conference on Natural Language Generation (INLG). Dublin, Ireland.</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->

						<!-- publication entry -->

						<!-- publication entry -->

						<div class="blog-content">
							<h3>A Dialogue System for Indoor Wayfinding Using Text-Based Natural Language</h3>
							<ul class="blog-meta">
								<li>
									<i class="fa fa-user"></i>Cuayáhuitl, H.</li>
								<li>
									<i class="fa fa-user"></i>
									<a href="nina.html">Dethlefs, N.</a>
								</li>
								<li>
									<i class="fa fa-user"></i>Richter, K.-F.</li>
								<li>
									<i class="fa fa-user"></i>Tenbrink, T.</li>
								<li>
									<i class="fa fa-user"></i>Bateman, J.</li>
								<li>
								<a href="publications/cicling2010.pdf"><i class="fa fa-cloud-download"></i></a>PDF</li>
							</ul>
							<ul class="blog-meta">
								<abstract style="display:inline" ;>
									<details open style="display:inline;">
										<summary>
											<span style="color:#6195FF">Hide/Show Full Abstract</span>
										</summary>
										We present a dialogue system that automatically generates indoor route instructions in German when asked about locations, using text-based natural language input and output. The challenging task in this system is to provide the user with a compact set of accurate and comprehensible instructions. We describe our approach based on high-level instructions. The system is described with four main modules: natural language understanding, dialogue management, route instruction generation and natural language generation. We report an evaluation with users unfamiliar with the system — using the PARADISE evaluation framework — in a real environment and naturalistic setting. We present results with high user satisfaction, and discuss future directions for enhancing this kind of system with more sophisticated and intuitive interaction.
									</details>
								</abstract>
							</ul>
							<ul class="blog-meta">
								<li>2010. International Journal of Computational Linguistics and Applications. Vol. 1, No. 2, pp. 285-304. Posted presented
									at the 11th Conference on Intelligent Text Processing and Computational Linguistics (CICLing).</li>
							</ul>
							<!-- blog tags -->
							<div class="blog-tags">
								<h5>Tags :</h5>
								<a href="interactive_systems.html#publications">
									<i class="fa fa-tag"></i>Interactive Systems</a>
								<a href="nlp.html#publications">
									<i class="fa fa-tag"></i>Natural Language Processing</a>
							</div>
						</div>
						<!-- blog tags -->
					</div>


						
					</div>

					
					
					
				</main>

		</div>
		<!-- /Container -->

	</div>
	<!-- /Portfolio -->		



	<!-- Footer -->
	<footer id="footer" class="sm-padding bg-dark">

		<!-- Container -->
		<div class="container">

			<!-- Row -->
			<div class="row">

				<div class="col-md-12">

					<!-- footer logo -->
					<div class="footer-logo">
						<a href="index.html"><img src="img/logo-alt.png" alt="logo"></a>
					</div>
					<!-- /footer logo -->

					<!-- footer copyright -->
					<div class="footer-copyright">
						<p>Copyright © 2017. All Rights Reserved. Designed by <a href="https://colorlib.com" target="_blank">Colorlib</a></p>
					</div>
					<!-- /footer copyright -->

				</div>

			</div>
			<!-- /Row -->

		</div>
		<!-- /Container -->

	</footer>
	<!-- /Footer -->

	<!-- Back to top -->
	<div id="back-to-top"></div>
	<!-- /Back to top -->

	<!-- Preloader -->
	<div id="preloader">
		<div class="preloader">
			<span></span>
			<span></span>
			<span></span>
			<span></span>
		</div>
	</div>
	<!-- /Preloader -->

	<!-- jQuery Plugins -->
	<script type="text/javascript" src="js/jquery.min.js"></script>
	<script type="text/javascript" src="js/bootstrap.min.js"></script>
	<script type="text/javascript" src="js/owl.carousel.min.js"></script>
	<script type="text/javascript" src="js/jquery.magnific-popup.js"></script>
	<script type="text/javascript" src="js/main.js"></script>

</body>

</html>
